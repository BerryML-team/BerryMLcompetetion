{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한글 폰트 문제 해결 \n",
    "# matplotlib은 한글 폰트를 지원하지 않음\n",
    "# os정보\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# font_manager : 폰트 관리 모듈\n",
    "# rc : 폰트 변경 모듈\n",
    "from matplotlib import font_manager, rc\n",
    "# unicode 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic') # os가 macos\n",
    "elif platform.system() == 'Windows':\n",
    "    path = 'c:/Windows/Fonts/malgun.ttf' # os가 windows\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print(\"Unknown System\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "dataB = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsB.csv\")\n",
    "dataC = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsC.csv\")\n",
    "dataD = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsD.csv\")\n",
    "dataE = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsE.csv\")\n",
    "\n",
    "dataR = pd.read_excel(\"./Data/사전테스트-생육데이터.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주차 df 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DayToWeek():\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    ## datetime date, time 분리\n",
    "    datalist = [dataB, dataC, dataD, dataE]\n",
    "\n",
    "    ## datetime을 date로 변경 \n",
    "    for data in datalist:\n",
    "        data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "        data['date'] = data['datetime'].dt.date\n",
    "        data['time'] = data['datetime'].dt.hour\n",
    "    \n",
    "\n",
    "    base_dateB = datetime(2023, 10, 6)\n",
    "    base_dateC = datetime(2023, 9, 22)  \n",
    "    base_dateD = datetime(2023, 10, 18)  \n",
    "    base_dateE = datetime(2023, 9, 22)  \n",
    "\n",
    "    base_weekB = 4\n",
    "    base_weekC = 1\n",
    "    base_weekD = 4\n",
    "    base_weekE = 1\n",
    "\n",
    "    # 주차 계산 함수\n",
    "    def calculate_week(date, base_date, base_week):\n",
    "        base_date_timestamp = pd.Timestamp(base_date)\n",
    "\n",
    "        # 날짜 차이 계산\n",
    "        delta_days = (date - base_date_timestamp).dt.days\n",
    "\n",
    "        # 기준 주차에서 날짜 차이를 주 단위로 변환\n",
    "        week = base_week + delta_days // 7\n",
    "        return week\n",
    "\n",
    "\n",
    "    datesB = pd.to_datetime(dataB['date']) \n",
    "    datesC = pd.to_datetime(dataC['date']) \n",
    "    datesD = pd.to_datetime(dataD['date']) \n",
    "    datesE = pd.to_datetime(dataE['date']) \n",
    "\n",
    "    weeksB = calculate_week(datesB, base_dateB, base_weekB)\n",
    "    weeksC = calculate_week(datesC, base_dateC, base_weekC)\n",
    "    weeksD = calculate_week(datesD, base_dateD, base_weekD)\n",
    "    weeksE = calculate_week(datesE, base_dateE, base_weekE)\n",
    "\n",
    "    dataB['weeks'] = weeksB\n",
    "    dataC['weeks'] = weeksC\n",
    "    dataD['weeks'] = weeksD\n",
    "    dataE['weeks'] = weeksE\n",
    "\n",
    "    dataB.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정제 및 예측모델 함수화 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def merge_input_output(outputfileName,saveFilename):\n",
    "    #컬럼이름변경\n",
    "    dataR.rename(columns={'생육주사': '생육주차'}, inplace=True)\n",
    "\n",
    "    make_DayToWeek()\n",
    "    \n",
    "\n",
    "    # 주차와 input 데이터만 데이터셋으로 만듬\n",
    "    dataCC = dataC.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "    dataBB = dataB.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "    dataDD = dataD.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "    dataEE = dataE.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "\n",
    "    dataT = pd.concat([dataBB, dataCC, dataDD, dataEE], ignore_index=True)\n",
    "\n",
    "        # 주차와 input 데이터만 데이터셋으로 만듬\n",
    "    dataC2 = dataC.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "    dataB2 = dataB.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "    dataD2 = dataD.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "    dataE2 = dataE.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "\n",
    "    # CO2 컬럼 정규화\n",
    "    datalist2 = [dataB2, dataC2, dataD2, dataE2]\n",
    "\n",
    "    for data in datalist2:\n",
    "\n",
    "        min_x = data['innerCO2'] - data['innerCO2'].min()\n",
    "        min_max = data['innerCO2'].max() - data['innerCO2'].min()\n",
    "        \n",
    "        normalCO2 = min_x / min_max\n",
    "        data['CO2'] = normalCO2\n",
    "        \n",
    "\n",
    "    dataE2\n",
    "    dataT = pd.concat([dataB2, dataC2, dataD2, dataE2], ignore_index=True)\n",
    "\n",
    "    dataT.rename(columns={\"생육주차\":\"주차\"}, inplace=True)\n",
    "\n",
    "    pivot = pd.read_csv(f\"./Data/{outputfileName}.csv\",)\n",
    "    pivot.head()\\\n",
    "    \n",
    "    dataT.rename(columns={\"주차\":\"weeks\"}, inplace=True)\n",
    "    pivot.rename(columns={\"주차\":\"weeks\"}, inplace=True)     \n",
    "\n",
    "    pivot = pivot.iloc[:,1:]   \n",
    "\n",
    "    dataT[dataT['farm'] == 'B농가'].iloc[:, 1:]\n",
    "\n",
    "    list = ['B농가','C농가','D농가','E농가']\n",
    "\n",
    "    # for i in list:\n",
    "    grouopB = dataT[dataT['farm'] == 'B농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "    grouopC = dataT[dataT['farm'] == 'C농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "    grouopD = dataT[dataT['farm'] == 'D농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "    grouopE = dataT[dataT['farm'] == 'E농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "\n",
    "    grouopB_reset = grouopB.reset_index()\n",
    "    grouopC_reset = grouopC.reset_index()\n",
    "    grouopD_reset = grouopD.reset_index()\n",
    "    grouopE_reset = grouopE.reset_index()\n",
    "\n",
    "    grouopB_reset['시설아이디'] = 'B농가'\n",
    "    grouopC_reset['시설아이디'] = 'C농가'\n",
    "    grouopD_reset['시설아이디'] = 'D농가'\n",
    "    grouopE_reset['시설아이디'] = 'E농가'\n",
    "\n",
    "    # grouopB = pivot[pivot['시설아이디'] == 'B농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "    # grouopC = pivot[pivot['시설아이디'] == 'C농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "    # grouopD = pivot[pivot['시설아이디'] == 'D농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "    # grouopE = pivot[pivot['시설아이디'] == 'E농가'].iloc[:, 1:].groupby('weeks').mean()\n",
    "\n",
    "    # grouopB_out = grouopB.reset_index()\n",
    "    # grouopC_out = grouopC.reset_index()\n",
    "    # grouopD_out = grouopD.reset_index()\n",
    "    # grouopE_out = grouopE.reset_index()\n",
    "\n",
    "    # grouopB_out['시설아이디'] = 'B농가'\n",
    "    # grouopC_out['시설아이디'] = 'C농가'\n",
    "    # grouopD_out['시설아이디'] = 'D농가'\n",
    "    # grouopE_out['시설아이디'] = 'E농가'\n",
    "\n",
    "    # pivotData = pd.concat([grouopB_out,grouopC_out,grouopD_out,grouopD_out], ignore_index=True)\n",
    "    trainData = pd.concat([grouopB_reset,grouopC_reset,grouopD_reset,grouopE_reset], ignore_index=True)\n",
    "\n",
    "    # dataT = pd.concat([dataB2, dataC2, dataD2, dataE2], ignore_index=True)\n",
    "    df = pd.merge(pivot, trainData,\n",
    "                    on=['시설아이디', 'weeks'],\n",
    "                    how='inner'\n",
    "                )\n",
    "    # print(df)\n",
    "\n",
    "    df.to_csv(f'./Data/{saveFilename}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2428308815.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2428308815.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2428308815.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2428308815.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n"
     ]
    }
   ],
   "source": [
    "merge_input_output(outputfileName=\"pivot\",saveFilename=\"ML_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>시설아이디</th>\n",
       "      <th>weeks</th>\n",
       "      <th>조사일자</th>\n",
       "      <th>표본번호</th>\n",
       "      <th>관부직경</th>\n",
       "      <th>엽병장</th>\n",
       "      <th>엽수</th>\n",
       "      <th>엽장</th>\n",
       "      <th>엽폭</th>\n",
       "      <th>...</th>\n",
       "      <th>초장</th>\n",
       "      <th>최종화방차수</th>\n",
       "      <th>화방 꽃수(소화수)</th>\n",
       "      <th>supplyEC</th>\n",
       "      <th>supplyPH</th>\n",
       "      <th>innerCO2</th>\n",
       "      <th>innerHum</th>\n",
       "      <th>innerTemp</th>\n",
       "      <th>innerSolar</th>\n",
       "      <th>CO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B농가</td>\n",
       "      <td>4</td>\n",
       "      <td>20231006</td>\n",
       "      <td>1</td>\n",
       "      <td>12.39</td>\n",
       "      <td>139.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934939</td>\n",
       "      <td>5.998963</td>\n",
       "      <td>928.372744</td>\n",
       "      <td>79.071951</td>\n",
       "      <td>15.957256</td>\n",
       "      <td>120.365122</td>\n",
       "      <td>0.885022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B농가</td>\n",
       "      <td>4</td>\n",
       "      <td>20231006</td>\n",
       "      <td>2</td>\n",
       "      <td>12.59</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934939</td>\n",
       "      <td>5.998963</td>\n",
       "      <td>928.372744</td>\n",
       "      <td>79.071951</td>\n",
       "      <td>15.957256</td>\n",
       "      <td>120.365122</td>\n",
       "      <td>0.885022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B농가</td>\n",
       "      <td>4</td>\n",
       "      <td>20231006</td>\n",
       "      <td>3</td>\n",
       "      <td>13.91</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934939</td>\n",
       "      <td>5.998963</td>\n",
       "      <td>928.372744</td>\n",
       "      <td>79.071951</td>\n",
       "      <td>15.957256</td>\n",
       "      <td>120.365122</td>\n",
       "      <td>0.885022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B농가</td>\n",
       "      <td>4</td>\n",
       "      <td>20231006</td>\n",
       "      <td>4</td>\n",
       "      <td>10.36</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934939</td>\n",
       "      <td>5.998963</td>\n",
       "      <td>928.372744</td>\n",
       "      <td>79.071951</td>\n",
       "      <td>15.957256</td>\n",
       "      <td>120.365122</td>\n",
       "      <td>0.885022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B농가</td>\n",
       "      <td>4</td>\n",
       "      <td>20231006</td>\n",
       "      <td>5</td>\n",
       "      <td>9.48</td>\n",
       "      <td>203.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>307.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934939</td>\n",
       "      <td>5.998963</td>\n",
       "      <td>928.372744</td>\n",
       "      <td>79.071951</td>\n",
       "      <td>15.957256</td>\n",
       "      <td>120.365122</td>\n",
       "      <td>0.885022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 시설아이디  weeks      조사일자  표본번호   관부직경    엽병장   엽수    엽장    엽폭  \\\n",
       "0           0   B농가      4  20231006     1  12.39  139.0  5.0  79.0  70.0   \n",
       "1           1   B농가      4  20231006     2  12.59  146.0  5.0  78.0  77.0   \n",
       "2           2   B농가      4  20231006     3  13.91  100.0  6.0  73.0  68.0   \n",
       "3           3   B농가      4  20231006     4  10.36  111.0  4.0  83.0  80.0   \n",
       "4           4   B농가      4  20231006     5   9.48  203.0  3.0  94.0  94.0   \n",
       "\n",
       "   ...     초장  최종화방차수  화방 꽃수(소화수)  supplyEC  supplyPH    innerCO2   innerHum  \\\n",
       "0  ...  255.0     0.0         0.0  0.934939  5.998963  928.372744  79.071951   \n",
       "1  ...  251.0     0.0         0.0  0.934939  5.998963  928.372744  79.071951   \n",
       "2  ...  209.0     0.0         0.0  0.934939  5.998963  928.372744  79.071951   \n",
       "3  ...  264.0     0.0         0.0  0.934939  5.998963  928.372744  79.071951   \n",
       "4  ...  307.0     0.0         0.0  0.934939  5.998963  928.372744  79.071951   \n",
       "\n",
       "   innerTemp  innerSolar       CO2  \n",
       "0  15.957256  120.365122  0.885022  \n",
       "1  15.957256  120.365122  0.885022  \n",
       "2  15.957256  120.365122  0.885022  \n",
       "3  15.957256  120.365122  0.885022  \n",
       "4  15.957256  120.365122  0.885022  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_mean = pd.read_csv(\"Data/ML_mean.csv\")\n",
    "ml_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import joblib\n",
    "\n",
    "def MultiOutputRegressorFunc_KNN(df, saveFileName):\n",
    "\n",
    "    \n",
    "    # Define features and targets\n",
    "    # features = ['supplyEC', 'supplyPH', 'innerCO2', 'innerHum', 'innerTemp', 'CO2']\n",
    "    features = ['innerCO2', 'innerHum', 'innerTemp', 'CO2']\n",
    "    targets = ['관부직경', '엽병장', '엽수', '엽장', '엽폭', '개화수', '초장', '최종화방차수', '화방 꽃수(소화수)']\n",
    "    \n",
    "    # Prepare the input and target data\n",
    "    X = df[features]\n",
    "    y = df[targets]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize KNN regressor\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=3)\n",
    "    \n",
    "    # Initialize and fit MultiOutputRegressor\n",
    "    multi_output_regressor = MultiOutputRegressor(knn_regressor)\n",
    "    multi_output_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = multi_output_regressor.score(X_test, y_test)\n",
    "    print(f'Model score: {score}')\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = multi_output_regressor.predict(X_test)\n",
    "    \n",
    "    # Print some example predictions\n",
    "    print(\"\\nExample predictions:\")\n",
    "    print(\"실제값\".ljust(15), *[f\"{target[:7]:7}\" for target in targets])\n",
    "    print(\"예측값\".ljust(15), *[f\"{target[:7]:7}\" for target in targets])\n",
    "    print(\"-\" * 100)\n",
    "    for i in range(min(5, len(predictions))):  # Print first 5 predictions\n",
    "        print(\"실제값\".ljust(15), *[f\"{val:7.2f}\" for val in y_test.iloc[i]])\n",
    "        print(\"예측값\".ljust(15), *[f\"{val:7.2f}\" for val in predictions[i]])\n",
    "        print(\"-\" * 100)\n",
    "    \n",
    "    # # Save the model\n",
    "    # filename = f'../Server/MLModels/{saveFileName}.joblib'\n",
    "    # print(f\"\\n모델을 {filename}에 저장합니다.\")\n",
    "    # joblib.dump(multi_output_regressor, filename)\n",
    "    \n",
    "    return multi_output_regressor\n",
    "\n",
    "# 사용 예시:\n",
    "# df = pd.read_csv('your_data.csv')  # 데이터 로드\n",
    "# model = MultiOutputRegressorFunc_KNN(df, 'multioutput_knn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "def MultiOutputRegressorFunc_RF(df, saveFileName):\n",
    "\n",
    "    \n",
    "    # Define features and targets\n",
    "    # features = ['supplyEC', 'supplyPH', 'innerCO2', 'inne2']\n",
    "    features = [ 'innerCO2', 'innerHum', 'innerTemp', 'CO2']\n",
    "    targets = ['관부직경', '엽병장', '엽수', '엽장', '엽폭', '개화수', '초장', '최종화방차수', '화방 꽃수(소화수)']\n",
    "    \n",
    "    # Prepare the input and target data\n",
    "    X = df[features]\n",
    "    y = df[targets]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize Random Forest regressor\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=150, random_state=42)\n",
    "    \n",
    "    # Initialize and fit MultiOutputRegressor\n",
    "    multi_output_regressor = MultiOutputRegressor(rf_regressor)\n",
    "    multi_output_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = multi_output_regressor.score(X_test, y_test)\n",
    "    print(f'Model score: {score}')\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = multi_output_regressor.predict(X_test)\n",
    "    \n",
    "    # Print some example predictions\n",
    "    print(\"\\nExample predictions:\")\n",
    "    print(\"실제값\".ljust(15), *[f\"{target[:7]:7}\" for target in targets])\n",
    "    print(\"예측값\".ljust(15), *[f\"{target[:7]:7}\" for target in targets])\n",
    "    print(\"-\" * 100)\n",
    "    for i in range(min(5, len(predictions))):  # Print first 5 predictions\n",
    "        print(\"실제값\".ljust(15), *[f\"{val:7.2f}\" for val in y_test.iloc[i]])\n",
    "        print(\"예측값\".ljust(15), *[f\"{val:7.2f}\" for val in predictions[i]])\n",
    "        print(\"-\" * 100)\n",
    "    \n",
    "    # Calculate and print feature importances\n",
    "    feature_importances = np.mean([tree.feature_importances_ for tree in multi_output_regressor.estimators_], axis=0)\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    for feature, importance in zip(features, feature_importances):\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "    # # Save the model\n",
    "    # filename = f'../Server/MLModels/{saveFileName}.joblib'\n",
    "    # print(f\"\\n모델을 {filename}에 저장합니다.\")\n",
    "    # joblib.dump(multi_output_regressor, filename)\n",
    "    \n",
    "    return multi_output_regressor\n",
    "\n",
    "# 사용 예시:\n",
    "# df = pd.read_csv('your_data.csv')  # 데이터 로드\n",
    "# model = MultiOutputRegressorFunc_RF(df, 'multioutput_rf_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기초통계량 column 추가 함수 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def merge_input_output(outputfileName, saveFilename):\n",
    "#     # 데이터 전처리\n",
    "#     dataR.rename(columns={'생육주사': '생육주차'}, inplace=True)\n",
    "#     make_DayToWeek()  # 이 함수는 별도로 정의되어 있어야 합니다\n",
    "\n",
    "#     # 농가별 데이터 추출\n",
    "#     farms = ['B', 'C', 'D', 'E']\n",
    "#     data_dict = {}\n",
    "#     for farm in farms:\n",
    "#         data_dict[farm] = globals()[f'data{farm}'].iloc[:, [0,2,3,4,5,6,7,10]]\n",
    "        \n",
    "#         # CO2 정규화\n",
    "#         min_x = data_dict[farm]['innerCO2'] - data_dict[farm]['innerCO2'].min()\n",
    "#         min_max = data_dict[farm]['innerCO2'].max() - data_dict[farm]['innerCO2'].min()\n",
    "#         data_dict[farm]['CO2'] = min_x / min_max\n",
    "\n",
    "#     # 데이터 병합\n",
    "#     dataT = pd.concat(list(data_dict.values()), ignore_index=True)\n",
    "#     dataT.rename(columns={\"생육주차\": \"weeks\"}, inplace=True)\n",
    "\n",
    "#     # pivot 데이터 읽기\n",
    "#     pivot = pd.read_csv(f\"./Data/{outputfileName}.csv\")\n",
    "#     pivot.rename(columns={\"주차\": \"weeks\"}, inplace=True)\n",
    "#     pivot = pivot.iloc[:, 1:]\n",
    "\n",
    "#     def calculate_stats(group):\n",
    "#         if isinstance(group, pd.Series):\n",
    "#             return pd.Series({\n",
    "#                 'mean': group.mean(),\n",
    "#                 'max': group.max(),\n",
    "#                 'min': group.min(),\n",
    "#                 'sum': group.sum(),\n",
    "#                 'std': group.std()\n",
    "#             })\n",
    "#         else:\n",
    "#             numeric_cols = group.select_dtypes(include=[np.number]).columns\n",
    "#             return pd.Series({\n",
    "#                 'mean': group[numeric_cols].mean(),\n",
    "#                 'max': group[numeric_cols].max(),\n",
    "#                 'min': group[numeric_cols].min(),\n",
    "#                 'sum': group[numeric_cols].sum(),\n",
    "#                 'std': group[numeric_cols].std()\n",
    "#             })\n",
    "\n",
    "#     stats_dfs = []\n",
    "#     for farm in farms:\n",
    "#         # dataT에 대한 통계\n",
    "#         farm_data = dataT[dataT['farm'] == f'{farm}농가'].iloc[:, 1:]\n",
    "#         numeric_cols = farm_data.select_dtypes(include=[np.number]).columns\n",
    "#         group_dataT = farm_data.groupby('weeks').agg({col: calculate_stats for col in numeric_cols})\n",
    "#         group_dataT = group_dataT.reset_index()\n",
    "#         group_dataT.columns = ['weeks'] + [f'{col[0]}_{col[1]}_input' for col in group_dataT.columns[1:]]\n",
    "#         group_dataT['시설아이디'] = f'{farm}농가'\n",
    "        \n",
    "#         # pivot에 대한 통계\n",
    "#         farm_pivot = pivot[pivot['시설아이디'] == f'{farm}농가'].iloc[:, 1:]\n",
    "#         numeric_cols = farm_pivot.select_dtypes(include=[np.number]).columns\n",
    "#         group_pivot = farm_pivot.groupby('weeks').agg({col: calculate_stats for col in numeric_cols})\n",
    "#         group_pivot = group_pivot.reset_index()\n",
    "#         group_pivot.columns = ['weeks'] + [f'{col[0]}_{col[1]}_output' for col in group_pivot.columns[1:]]\n",
    "        \n",
    "#         # dataT와 pivot 통계 병합\n",
    "#         merged_stats = pd.merge(group_dataT, group_pivot, on=['weeks'])\n",
    "#         stats_dfs.append(merged_stats)\n",
    "\n",
    "#     # 모든 농가의 통계를 하나의 DataFrame으로 결합\n",
    "#     all_stats = pd.concat(stats_dfs, ignore_index=True)\n",
    "\n",
    "#     # 원본 데이터와 통계 데이터 병합\n",
    "#     result = pd.merge(pivot, all_stats, on=['시설아이디', 'weeks'], how='inner')\n",
    "\n",
    "#     # 결과를 CSV 파일로 저장\n",
    "#     result.to_csv(f'./Data/{saveFilename}.csv', index=False)\n",
    "\n",
    "#     # return result\n",
    "\n",
    "# # 함수 호출\n",
    "# # result_df = merge_input_output('output_file_name', 'save_file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2662713123.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_dict[farm]['CO2'] = min_x / min_max\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2662713123.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_dict[farm]['CO2'] = min_x / min_max\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2662713123.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_dict[farm]['CO2'] = min_x / min_max\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_36196/2662713123.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_dict[farm]['CO2'] = min_x / min_max\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must produce aggregated value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merge_input_output(outputfileName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m,saveFilename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mML_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 54\u001b[0m, in \u001b[0;36mmerge_input_output\u001b[0;34m(outputfileName, saveFilename)\u001b[0m\n\u001b[1;32m     52\u001b[0m farm_data \u001b[38;5;241m=\u001b[39m dataT[dataT[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfarm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfarm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m농가\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     53\u001b[0m numeric_cols \u001b[38;5;241m=\u001b[39m farm_data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m---> 54\u001b[0m group_dataT \u001b[38;5;241m=\u001b[39m farm_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweeks\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({col: calculate_stats \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols})\n\u001b[1;32m     55\u001b[0m group_dataT \u001b[38;5;241m=\u001b[39m group_dataT\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     56\u001b[0m group_dataT\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweeks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m group_dataT\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1445\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1442\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m   1444\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m-> 1445\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:175\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:406\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_dict_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1390\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[1;32m   1388\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1389\u001b[0m ):\n\u001b[0;32m-> 1390\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dict_like(\n\u001b[1;32m   1391\u001b[0m         op_name, selected_obj, selection, kwargs\n\u001b[1;32m   1392\u001b[0m     )\n\u001b[1;32m   1393\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:479\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), op_name)(how, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    482\u001b[0m     ]\n\u001b[1;32m    483\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:480\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    476\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m    479\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 480\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), op_name)(how, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    482\u001b[0m     ]\n\u001b[1;32m    483\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:292\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:325\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[0;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(obj, f)\n\u001b[1;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mconstruct_array_type()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:882\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    878\u001b[0m res \u001b[38;5;241m=\u001b[39m extract_result(res)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m     check_result_array(res, group\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    883\u001b[0m     initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    885\u001b[0m result[i] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:89\u001b[0m, in \u001b[0;36mcheck_result_array\u001b[0;34m(obj, dtype)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;66;03m# If it is object dtype, the function can be a reduction/aggregation\u001b[39;00m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;66;03m#  and still return an ndarray e.g. test_agg_over_numpy_arrays\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust produce aggregated value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Must produce aggregated value"
     ]
    }
   ],
   "source": [
    "# merge_input_output(outputfileName=\"pivot\",saveFilename=\"ML_mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/ML_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiOutputRegressorFunc_RF(df=df,saveFileName=\"finaltest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiOutputRegressorFunc_KNN(df=df,saveFileName=\"finaltest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
