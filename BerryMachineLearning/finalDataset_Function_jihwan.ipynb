{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "dataB = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsB.csv\")\n",
    "dataC = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsC.csv\")\n",
    "dataD = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsD.csv\")\n",
    "dataE = pd.read_csv(\"./Data/사전테스트-환경데이터/environmentsE.csv\")\n",
    "\n",
    "dataR = pd.read_excel(\"./Data/사전테스트-생육데이터.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DayToWeek():\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    ## datetime date, time 분리\n",
    "    datalist = [dataB, dataC, dataD, dataE]\n",
    "\n",
    "    ## datetime을 date로 변경 \n",
    "    for data in datalist:\n",
    "        data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "        data['date'] = data['datetime'].dt.date\n",
    "        data['time'] = data['datetime'].dt.hour\n",
    "    \n",
    "\n",
    "    base_dateB = datetime(2023, 10, 6)\n",
    "    base_dateC = datetime(2023, 9, 22)  \n",
    "    base_dateD = datetime(2023, 10, 18)  \n",
    "    base_dateE = datetime(2023, 9, 22)  \n",
    "\n",
    "    base_weekB = 4\n",
    "    base_weekC = 1\n",
    "    base_weekD = 4\n",
    "    base_weekE = 1\n",
    "\n",
    "    # 주차 계산 함수\n",
    "    def calculate_week(date, base_date, base_week):\n",
    "        base_date_timestamp = pd.Timestamp(base_date)\n",
    "\n",
    "        # 날짜 차이 계산\n",
    "        delta_days = (date - base_date_timestamp).dt.days\n",
    "\n",
    "        # 기준 주차에서 날짜 차이를 주 단위로 변환\n",
    "        week = base_week + delta_days // 7\n",
    "        return week\n",
    "\n",
    "\n",
    "    datesB = pd.to_datetime(dataB['date']) \n",
    "    datesC = pd.to_datetime(dataC['date']) \n",
    "    datesD = pd.to_datetime(dataD['date']) \n",
    "    datesE = pd.to_datetime(dataE['date']) \n",
    "\n",
    "    weeksB = calculate_week(datesB, base_dateB, base_weekB)\n",
    "    weeksC = calculate_week(datesC, base_dateC, base_weekC)\n",
    "    weeksD = calculate_week(datesD, base_dateD, base_weekD)\n",
    "    weeksE = calculate_week(datesE, base_dateE, base_weekE)\n",
    "\n",
    "    dataB['weeks'] = weeksB\n",
    "    dataC['weeks'] = weeksC\n",
    "    dataD['weeks'] = weeksD\n",
    "    dataE['weeks'] = weeksE\n",
    "\n",
    "    dataB.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def merge_input_output(saveFilename):\n",
    "    #컬럼이름변경\n",
    "    # dataR.rename(columns={'생육주사': '주차'}, inplace=True)\n",
    "\n",
    "        # 전체 데이터를 사용하여 피벗 테이블을 생성합니다\n",
    "    # '시설아이디' 유무에 따른 row 갯수 오류 확인하기\n",
    "    # pivot = pd.pivot_table(dataR, \n",
    "    #                         values='조사항목값', \n",
    "    #                         index=['시설아이디','생육주사', '조사일자', '표본번호'], \n",
    "    #                         columns='조사항목', \n",
    "    #                         aggfunc='first')\n",
    "    # print(pivot)\n",
    "    # # 인덱스를 리셋합니다\n",
    "    # pivot = pivot.reset_index()\n",
    "    # pivot = pivot.rename(columns={'생육주사': '주차','착과수': '개화수'})\n",
    "    pivot = pd.read_csv(f\"./Data/pivot.csv\",)\n",
    "    # pivot.head()\n",
    "    make_DayToWeek()\n",
    "    \n",
    "\n",
    "    # 주차와 input 데이터만 데이터셋으로 만듬\n",
    "    dataCC = dataC.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "    dataBB = dataB.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "    dataDD = dataD.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "    dataEE = dataE.iloc[: ,[2,3,4,5,6,7,10]]\n",
    "\n",
    "    dataT = pd.concat([dataBB, dataCC, dataDD, dataEE], ignore_index=True)\n",
    "\n",
    "        # 주차와 input 데이터만 데이터셋으로 만듬\n",
    "    dataC2 = dataC.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "    dataB2 = dataB.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "    dataD2 = dataD.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "    dataE2 = dataE.iloc[: ,[0,2,3,4,5,6,7,10]]\n",
    "\n",
    "    # CO2 컬럼 정규화\n",
    "    datalist2 = [dataB2, dataC2, dataD2, dataE2]\n",
    "\n",
    "    for data in datalist2:\n",
    "\n",
    "        min_x = data['innerCO2'] - data['innerCO2'].min()\n",
    "        min_max = data['innerCO2'].max() - data['innerCO2'].min()\n",
    "        \n",
    "        normalCO2 = min_x / min_max\n",
    "        data['CO2'] = normalCO2\n",
    "        \n",
    "\n",
    "    dataE2\n",
    "    dataT = pd.concat([dataB2, dataC2, dataD2, dataE2], ignore_index=True)\n",
    "\n",
    "    dataT.rename(columns={\"생육주차\":\"주차\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    dataT.rename(columns={\"주차\":\"weeks\"}, inplace=True)\n",
    "    pivot.rename(columns={\"주차\":\"weeks\"}, inplace=True)     \n",
    "    # dataT에서 7주차 D농가 데이터 삭제\n",
    "    dataT = dataT[~((dataT['weeks'] == 7) & (dataT['farm'] == 'D농가'))]\n",
    "\n",
    "    # pivot에서 7주차 D농가 데이터 삭제\n",
    "    pivot = pivot[~((pivot['weeks'] == 7) & (pivot['시설아이디'] == 'D농가'))]\n",
    "    pivot = pivot.iloc[:,1:]   \n",
    "\n",
    "    dataT[dataT['farm'] == 'B농가'].iloc[:, 1:]\n",
    "\n",
    "    farms = ['B', 'C', 'D', 'E']\n",
    "    group_stats = {}\n",
    "\n",
    "    for farm in farms:\n",
    "        farm_data = dataT[dataT['farm'] == f'{farm}농가'].iloc[:, 1:]\n",
    "        group_stats[farm] = farm_data.groupby('weeks').agg(['sum', 'mean', 'min', 'max', 'std','var','median'])\n",
    "        \n",
    "        # 열 이름 변경\n",
    "        group_stats[farm].columns = [f'{col[0]}_{col[1]}' for col in group_stats[farm].columns]\n",
    "        \n",
    "        # 인덱스 리셋 및 시설아이디 추가\n",
    "        group_stats[farm] = group_stats[farm].reset_index()\n",
    "        group_stats[farm]['시설아이디'] = f'{farm}농가'\n",
    "\n",
    "    # 모든 농가의 데이터를 하나로 합치기\n",
    "    result = pd.concat([group_stats[farm] for farm in farms], ignore_index=True)\n",
    "\n",
    "    # pivot 데이터와 병합 (필요한 경우)\n",
    "    result = pd.merge(pivot, result, on=['시설아이디', 'weeks'], how='inner')\n",
    "    print(result.head())\n",
    "    # 결과를 CSV 파일로 저장\n",
    "    result.to_csv(f'./Data/{saveFilename}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조사항목                       관부직경    엽병장   엽수    엽장    엽폭  착과수     초장  최종화방차수  \\\n",
      "시설아이디 생육주사 조사일자     표본번호                                                      \n",
      "B농가   4    20231006 1     12.39  139.0  5.0  79.0  70.0  0.0  255.0     0.0   \n",
      "                    2     12.59  146.0  5.0  78.0  77.0  0.0  251.0     0.0   \n",
      "                    3     13.91  100.0  6.0  73.0  68.0  0.0  209.0     0.0   \n",
      "                    4     10.36  111.0  4.0  83.0  80.0  0.0  264.0     0.0   \n",
      "                    5      9.48  203.0  3.0  94.0  94.0  0.0  307.0     0.0   \n",
      "...                         ...    ...  ...   ...   ...  ...    ...     ...   \n",
      "E농가   32   20240426 5     19.17  220.0  7.0  78.0  70.0  0.0  352.0     3.0   \n",
      "                    6     29.35  307.0  6.0  97.0  87.0  0.0  480.0     3.0   \n",
      "                    7     29.94  288.0  8.0  83.0  70.0  0.0  452.0     3.0   \n",
      "                    8     23.65  319.0  4.0  95.0  81.0  0.0  495.0     3.0   \n",
      "                    9     27.90  292.0  8.0  80.0  71.0  0.0  421.0     3.0   \n",
      "\n",
      "조사항목                      화방 꽃수(소화수)  \n",
      "시설아이디 생육주사 조사일자     표본번호              \n",
      "B농가   4    20231006 1            0.0  \n",
      "                    2            0.0  \n",
      "                    3            0.0  \n",
      "                    4            0.0  \n",
      "                    5            0.0  \n",
      "...                              ...  \n",
      "E농가   32   20240426 5            0.0  \n",
      "                    6            0.0  \n",
      "                    7            0.0  \n",
      "                    8            0.0  \n",
      "                    9            0.0  \n",
      "\n",
      "[1097 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_61528/872618914.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_61528/872618914.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_61528/872618914.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n",
      "/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_61528/872618914.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CO2'] = normalCO2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'시설아이디'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_61528/2761613340.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerge_input_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ML_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5b/bk7dwjqs57d1fzmtyxy952540000gn/T/ipykernel_61528/872618914.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(saveFilename)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# 모든 농가의 데이터를 하나로 합치기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfarm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfarm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfarms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# pivot 데이터와 병합 (필요한 경우)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'시설아이디'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weeks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# 결과를 CSV 파일로 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./Data/{saveFilename}.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         )\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '시설아이디'"
     ]
    }
   ],
   "source": [
    "merge_input_output(saveFilename=\"ML_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"Data/ML_final.csv\")\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
